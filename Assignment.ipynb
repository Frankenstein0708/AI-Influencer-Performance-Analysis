{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "986d634c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Analysis Complete!\n",
      "Check 'performance_summary.txt' for detailed insights\n",
      "Check 'performance_details.csv' for full dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nVideo Performance Analysis Tool\\n\\nKey Outputs:\\n1. performance_summary.txt\\n   - Overall performance statistics\\n   - Performance distribution\\n   - Top and bottom performing videos\\n\\n2. performance_details.csv\\n   - Full dataset with performance details\\n\\nPrerequisites:\\n- Install pandas: pip install pandas\\n\\nUsage:\\n1. Ensure CSV has 'Performance' and 'Video URL' columns\\n2. Replace 'performance_data.csv' with your file path\\n3. Run the script\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def analyze_video_performance(csv_path):\n",
    "    \"\"\"\n",
    "    Perform basic analysis of video performance data\n",
    "    \n",
    "    Args:\n",
    "        csv_path (str): Path to CSV file with performance and video URLs\n",
    "    \n",
    "    Returns:\n",
    "        dict: Key performance insights\n",
    "    \"\"\"\n",
    "    # Read the CSV file\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Ensure numeric performance column\n",
    "        df['Performance'] = pd.to_numeric(df['Performance'], errors='coerce')\n",
    "        df = df.dropna(subset=['Performance'])\n",
    "        \n",
    "        # Basic performance analysis\n",
    "        performance_analysis = {\n",
    "            'Total Videos': len(df),\n",
    "            'Average Performance': df['Performance'].mean(),\n",
    "            'Median Performance': df['Performance'].median(),\n",
    "            'Performance Std Dev': df['Performance'].std(),\n",
    "            'Min Performance': df['Performance'].min(),\n",
    "            'Max Performance': df['Performance'].max()\n",
    "        }\n",
    "        \n",
    "        # Top 5 and Bottom 5 performing videos\n",
    "        top_5 = df.nlargest(5, 'Performance')[['Performance', 'Video URL']]\n",
    "        bottom_5 = df.nsmallest(5, 'Performance')[['Performance', 'Video URL']]\n",
    "        \n",
    "        # Performance distribution\n",
    "        performance_bins = pd.cut(\n",
    "            df['Performance'], \n",
    "            bins=4, \n",
    "            labels=['Low', 'Medium-Low', 'Medium-High', 'High']\n",
    "        )\n",
    "        performance_distribution = performance_bins.value_counts(normalize=True) * 100\n",
    "        \n",
    "        # Export results\n",
    "        with open('performance_summary.txt', 'w') as f:\n",
    "            f.write(\"Performance Analysis Summary\\n\")\n",
    "            f.write(\"==========================\\n\\n\")\n",
    "            f.write(\"Overall Statistics:\\n\")\n",
    "            for stat, value in performance_analysis.items():\n",
    "                f.write(f\"{stat}: {value:.2f}\\n\")\n",
    "            \n",
    "            f.write(\"\\n\\nPerformance Distribution:\\n\")\n",
    "            for category, percentage in performance_distribution.items():\n",
    "                f.write(f\"{category}: {percentage:.2f}%\\n\")\n",
    "            \n",
    "            f.write(\"\\n\\nTop 5 Performing Videos:\\n\")\n",
    "            f.write(top_5.to_string())\n",
    "            \n",
    "            f.write(\"\\n\\nBottom 5 Performing Videos:\\n\")\n",
    "            f.write(bottom_5.to_string())\n",
    "        \n",
    "        # Save detailed data\n",
    "        df.to_csv('performance_details.csv', index=False)\n",
    "        \n",
    "        return performance_analysis\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing performance: {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    # Analyze performance from CSV\n",
    "    result = analyze_video_performance('assignmentData.csv')\n",
    "    \n",
    "    # Print key insights\n",
    "    if result:\n",
    "        print(\"Performance Analysis Complete!\")\n",
    "        print(\"Check 'performance_summary.txt' for detailed insights\")\n",
    "        print(\"Check 'performance_details.csv' for full dataset\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "# README\n",
    "\"\"\"\n",
    "Video Performance Analysis Tool\n",
    "\n",
    "Key Outputs:\n",
    "1. performance_summary.txt\n",
    "   - Overall performance statistics\n",
    "   - Performance distribution\n",
    "   - Top and bottom performing videos\n",
    "\n",
    "2. performance_details.csv\n",
    "   - Full dataset with performance details\n",
    "\n",
    "Prerequisites:\n",
    "- Install pandas: pip install pandas\n",
    "\n",
    "Usage:\n",
    "1. Ensure CSV has 'Performance' and 'Video URL' columns\n",
    "2. Replace 'performance_data.csv' with your file path\n",
    "3. Run the script\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dc21bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract frames from videos\n",
    "def extract_frames(video_path, output_folder, interval=2):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_rate = cap.get(cv2.CAP_PROP_FPS)  # Frame rate of the video\n",
    "    count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if int(count % (frame_rate * interval)) == 0:  # Extract every `interval` seconds\n",
    "            frame_filename = os.path.join(output_folder, f\"frame_{count}.jpg\")\n",
    "            cv2.imwrite(frame_filename, frame)\n",
    "        count += 1\n",
    "    cap.release()\n",
    "    print(f\"Frames saved to {output_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ed28bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Detect faces and extract features\n",
    "def get_face_embeddings(image_path):\n",
    "    image = face_recognition.load_image_file(image_path)\n",
    "    face_locations = face_recognition.face_locations(image)\n",
    "    face_encodings = face_recognition.face_encodings(image, face_locations)\n",
    "    \n",
    "    if face_encodings:\n",
    "        return face_encodings[0]  # Return the first face detected\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_visual_features(image_path):\n",
    "    img = image.load_img(image_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "    features = model.predict(x)\n",
    "    return features.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb3d42c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Clustering the face embeddings and visual features\n",
    "def cluster_faces_and_visuals(embeddings, features, eps=0.5, min_samples=2):\n",
    "    combined_features = np.concatenate([embeddings, features], axis=1)\n",
    "    clustering_model = DBSCAN(eps=eps, min_samples=min_samples, metric='cosine')\n",
    "    cluster_labels = clustering_model.fit_predict(combined_features)\n",
    "    return cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d5a11bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Calculate average performance for each influencer (cluster)\n",
    "def calculate_avg_performance(df, cluster_labels):\n",
    "    df['cluster'] = cluster_labels\n",
    "    avg_performance = df.groupby('cluster')['Performance'].mean()\n",
    "    return avg_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eca8649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Complete pipeline\n",
    "def process_videos_and_calculate_performance(video_urls, output_folder):\n",
    "    all_face_embeddings = []\n",
    "    all_visual_features = []\n",
    "    video_performance = []  # Store video performance for later mapping\n",
    "\n",
    "    for video_url in video_urls:\n",
    "        video_path = download_video(video_url)  # You may download the video here\n",
    "        frames_folder = os.path.join(output_folder, os.path.basename(video_url))\n",
    "        extract_frames(video_path, frames_folder)\n",
    "\n",
    "        for frame_file in os.listdir(frames_folder):\n",
    "            frame_path = os.path.join(frames_folder, frame_file)\n",
    "            embeddings = get_face_embeddings(frame_path)  # Try face_recognition first\n",
    "            if embeddings is None:\n",
    "                embeddings = extract_visual_features(frame_path)  # Fallback to ResNet features\n",
    "\n",
    "            # Collect the embeddings and video performance\n",
    "            all_face_embeddings.append(embeddings)\n",
    "            all_visual_features.append(embeddings if embeddings is not None else np.zeros(512))  # Handle None case\n",
    "            video_performance.append(fetch_video_performance(video_url))  # You can get the performance from your data\n",
    "\n",
    "    # Perform clustering on the embeddings\n",
    "    cluster_labels = cluster_faces_and_visuals(all_face_embeddings, all_visual_features)\n",
    "    df = pd.DataFrame({'Video URL': video_urls, 'Performance': video_performance})\n",
    "    avg_performance = calculate_avg_performance(df, cluster_labels)\n",
    "\n",
    "    print(avg_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58406af4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
